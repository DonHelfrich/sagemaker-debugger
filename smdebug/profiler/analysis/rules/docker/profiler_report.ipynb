{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Debugger profiling report\n",
    "This report summarizes the execution of the profiler built-in rules. Profiler runs a set of rules as the training is going on where each of them identifies certain performance issues. This notebook gives a description for each rule and details about the rule execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from smdebug.profiler.utils import us_since_epoch_to_human_readable_time, ns_since_epoch_to_human_readable_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import bokeh\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.layouts import column, row\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models.widgets import DataTable, DateFormatter, TableColumn\n",
    "from bokeh.models import ColumnDataSource, PreText\n",
    "from math import pi\n",
    "from bokeh.transform import cumsum\n",
    "import warnings\n",
    "from bokeh.models.widgets import Paragraph\n",
    "from bokeh.models import Legend\n",
    "from bokeh.util.warnings import BokehDeprecationWarning, BokehUserWarning\n",
    "warnings.simplefilter('ignore', BokehDeprecationWarning)\n",
    "warnings.simplefilter('ignore', BokehUserWarning)\n",
    "\n",
    "output_notebook(hide_banner=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def create_piechart(data_dict, title=None, height=400, width=400, x1=0, x2=0.1, radius=0.4, toolbar_location='right'):\n",
    "   \n",
    "    plot = figure(plot_height=height, \n",
    "                  plot_width=width,\n",
    "                  toolbar_location=toolbar_location,\n",
    "                  tools=\"hover,wheel_zoom,reset,pan\", \n",
    "                  tooltips=\"@phase:@value\", \n",
    "                  title=title,\n",
    "                  x_range=(-radius-x1, radius+x2))\n",
    "\n",
    "    data = pd.Series(data_dict).reset_index(name='value').rename(columns={'index':'phase'})\n",
    "    data['angle'] = data['value']/data['value'].sum() * 2*pi\n",
    "    data['color'] = bokeh.palettes.viridis(len(data_dict))\n",
    "\n",
    "    plot.wedge(x=0, y=0., radius=radius,\n",
    "        start_angle=cumsum('angle', include_zero=True), \n",
    "        end_angle=cumsum('angle'),\n",
    "        line_color=\"white\", \n",
    "        source=data, \n",
    "        fill_color='color', \n",
    "        legend='phase'\n",
    "              )\n",
    "    plot.legend.label_text_font_size = \"8pt\"\n",
    "    plot.legend.location = 'center_right'\n",
    "    plot.axis.axis_label=None\n",
    "    plot.axis.visible=False\n",
    "    plot.grid.grid_line_color = None\n",
    "    plot.outline_line_color = \"white\"\n",
    "    \n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Markdown, Image\n",
    "def pretty_print(df):\n",
    "    raw_html = df.to_html().replace(\"\\\\n\",\"<br>\").replace('<tr>','<tr style=\"text-align: left;\">')\n",
    "    return display(HTML(raw_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training job summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def load_report(rule_name):\n",
    "    try:\n",
    "        report = json.load(open('/opt/ml/processing/outputs/profiler-reports/'+rule_name+'.json'))\n",
    "        if rule_name != 'MaxInitializationTime' and rule_name != 'OverallSystemUsage' and rule_name != 'OverallFrameworkMetrics':\n",
    "            triggered = report['RuleTriggered']\n",
    "            datapoints = report['Datapoints']\n",
    "            display(Markdown(f\"\"\"The number of times the {rule_name} rule triggerd: {triggered}\"\"\"))\n",
    "            display(Markdown(f\"\"\"The number of events processed by {rule_name} rule: {datapoints}\"\"\"))\n",
    "        return report\n",
    "    except FileNotFoundError:\n",
    "        print (rule_name + ' not triggered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "job_statistics = {}\n",
    "report = load_report('MaxInitializationTime')\n",
    "if report:\n",
    "    if \"first\" in report['Details'][\"step_num\"]:\n",
    "        first_step = report['Details'][\"step_num\"][\"first\"]\n",
    "        last_step = report['Details'][\"step_num\"][\"last\"]\n",
    "    job_statistics[\"start_time\"] = us_since_epoch_to_human_readable_time(report['Details']['job_start'] * 1000000)\n",
    "    job_statistics[\"end_time\"] = us_since_epoch_to_human_readable_time(report['Details']['job_end'] * 1000000)\n",
    "    job_statistics[\"job_duration_in_seconds\"] = (report['Details']['job_end'] - report['Details']['job_start']) \n",
    "    if \"first\" in report['Details'][\"step_num\"]:\n",
    "        job_statistics[\"training_loop_start\"] = us_since_epoch_to_human_readable_time(first_step)\n",
    "        job_statistics[\"training_loop_end\"] = us_since_epoch_to_human_readable_time(last_step)\n",
    "        job_statistics[\"training_loop_duration_in_seconds\"] = (last_step - first_step) / 1000000\n",
    "        job_statistics[\"initialization_in_seconds\"] = first_step/1000000 - report['Details']['job_start'] \n",
    "        job_statistics[\"finalization_in_seconds\"] = np.abs(report['Details']['job_end'] - last_step/1000000)\n",
    "        job_statistics[\"initialization_%\"] = job_statistics[\"initialization_in_seconds\"] / job_statistics[\"job_duration_in_seconds\"] * 100\n",
    "        job_statistics[\"training_loop_%\"] = job_statistics[\"training_loop_duration_in_seconds\"] / job_statistics[\"job_duration_in_seconds\"] * 100\n",
    "        job_statistics[\"finalization_%\"] = job_statistics[\"finalization_in_seconds\"] / job_statistics[\"job_duration_in_seconds\"] * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "text =  \"\"\"The following table gives a summary about the training job. The tables includes information about when the training job started and ended, how much time initialization, training loop and finalization took.\"\"\"\n",
    "if job_statistics:\n",
    "    df = pd.DataFrame.from_dict(job_statistics, orient='index')\n",
    "    start_time = df[0]['start_time']\n",
    "    date = datetime.datetime.strptime(df[0]['start_time'], '%Y-%m-%dT%H:%M:%S:%f')\n",
    "    day = date.date().strftime(\"%m/%d/%Y\")\n",
    "    hour = date.time().strftime(\"%H:%M:%S\")\n",
    "    duration = int(df[0]['job_duration_in_seconds'])\n",
    "    text = Paragraph(text=f\"\"\"{text} \\n Your training job started on {day} at {hour} and ran for {duration} seconds.\"\"\")\n",
    "     \n",
    "    #pretty_print(df)\n",
    "    if \"first\" in report['Details'][\"step_num\"]:\n",
    "        if job_statistics[\"finalization_%\"]  < 0:\n",
    "            job_statistics[\"finalization_%\"]  = 0\n",
    "        if job_statistics[\"training_loop_%\"] < 0:\n",
    "            job_statistics[\"training_loop_%\"] = 0\n",
    "        if job_statistics[\"initialization_%\"] < 0:\n",
    "            job_statistics[\"initialization_%\"] = 0\n",
    "    else:\n",
    "        text = Paragraph(text=f\"\"\"{text} \\n Your training job started on {day} at {hour} and ran for {duration} seconds.\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "df2 = df.reset_index()\n",
    "df2.columns = [\"0\", \"1\"]\n",
    "source = ColumnDataSource(data=df2)\n",
    "columns = [TableColumn(field='0', title=\"\"),\n",
    "           TableColumn(field='1', title=\"Job Statistics\"),]\n",
    "table = DataTable(source=source, columns=columns, width=450, height=380)\n",
    "plot = None\n",
    "if \"initialization_%\" in job_statistics:\n",
    "    piechart_data = {}\n",
    "    piechart_data[\"initialization_%\"] = job_statistics[\"initialization_%\"]  \n",
    "    piechart_data[\"training_loop_%\"]  = job_statistics[\"training_loop_%\"] \n",
    "    piechart_data[\"finalization_%\"]  = job_statistics[\"finalization_%\"] \n",
    "\n",
    "    plot = create_piechart(piechart_data, \n",
    "                           height=350,\n",
    "                           width=500,\n",
    "                           x1=0.15,\n",
    "                           x2=0.15,\n",
    "                           radius=0.15, \n",
    "                           toolbar_location=None)\n",
    "\n",
    "text=f\"\"\"Your training job started on {day} at {hour} and ran for {duration} seconds.\"\"\"\n",
    "if plot != None:\n",
    "    text = Paragraph(text=f\"\"\"{text}\"\"\", width = 800)\n",
    "    show(column(text, row(table, plot)))\n",
    "else:\n",
    "    text = Paragraph(text=f\"\"\"{text}. No step information was recorded in your training job, so initialization and finalization time cannot be computed.\"\"\" , width = 800)\n",
    "    show(column(text, row(table)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System usage statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "report = load_report('OverallSystemUsage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "if \"GPU\" in report[\"Details\"]:\n",
    "    for node_id in report[\"Details\"][\"GPU\"]:\n",
    "        gpu_p95 = report[\"Details\"][\"GPU\"][node_id][\"p95\"]\n",
    "        cpu_p95 = report[\"Details\"][\"CPU\"][node_id][\"p95\"]\n",
    "        text1 = ''\n",
    "        if gpu_p95 < 70 and cpu_p95 < 70:\n",
    "            text1 = f\"\"\"{text1}The 95th quantile of the total GPU utilization on node {node_id} is only {int(gpu_p95)}%. \n",
    "            The 95th quantile of the total CPU utilization is only {int(cpu_p95)}%. Node {node_id} is under-utilized. \n",
    "            You may want to consider switching to a smaller instance type.\"\"\"\n",
    "        elif gpu_p95 < 70 and cpu_p95 > 70:\n",
    "            text1 = f\"\"\"{text1}The 95th quantile of the total GPU utilization on node {node_id} is only {int(gpu_p95)}%. \n",
    "            However, the 95th quantile of the total CPU utilization is {int(cpu_p95)}%. GPUs on node {node_id} are under-utilized \n",
    "            likely because of CPU bottlenecks\"\"\"\n",
    "        elif gpu_p95 > 70:\n",
    "            text1 = f\"\"\"{text1}The 95th quantile of the total GPU utilization on node {node_id} is {int(gpu_p95)}%. \n",
    "            GPUs on node {node_id} are well utilized\"\"\"\n",
    "        else:\n",
    "            text1 = f\"\"\"{text1}The 95th quantile of the total GPU utilization on node {node_id} is {int(gpu_p95)}%. \n",
    "            The 95th quantile of the total CPU utilization is {int(cpu_p95)}%.\"\"\"\n",
    "else:\n",
    "    for node_id in report[\"Details\"][\"CPU\"]:\n",
    "        cpu_p95 = report[\"Details\"][\"CPU\"][node_id][\"p95\"]\n",
    "        if cpu_p95 > 70:\n",
    "            text1 = f\"\"\"{text1}The 95th quantile of the total CPU utilization on node {node_id} is {int**(cpu_p95)}%. GPUs on node {node_id} are well utilized\"\"\"\n",
    "text1 = Paragraph(text=f\"\"\"{text1}\"\"\", width=1100)\n",
    "text2 = Paragraph(text=f\"\"\"The following table shows usage statistics per worker node such as total CPU and GPU \n",
    "utilization, total CPU and memory footprint. The table also include total IO wait time and total sent/received bytes.\n",
    "The table shows min and max values as well as p99, p90 and p50 percentiles.\"\"\", width=900)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "rows = [] \n",
    "units = {\"CPU\": \"percentage\", \"CPU memory\": \"percentage\", \"GPU\": \"percentage\", \"Network\": \"bytes\", \"GPU memory\": \"percentage\", \"I/O\": \"percentage\"}\n",
    "if report:\n",
    "    for metric in report['Details']:\n",
    "        for node_id in report['Details'][metric]:\n",
    "            values = report['Details'][metric][node_id]\n",
    "            rows.append([node_id, metric, units[metric], values['max'], values['p99'], values['p95'], values['p50'], values['min']])\n",
    "\n",
    "    df = pd.DataFrame(rows) \n",
    "    df.columns = ['Node', 'metric', 'unit', 'max', 'p99', 'p95', 'p50', 'min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "df2 = df.reset_index()\n",
    "source = ColumnDataSource(data=df2)\n",
    "columns = [TableColumn(field='Node', title=\"node\"),\n",
    "           TableColumn(field='metric', title=\"metric\"),\n",
    "           TableColumn(field='unit', title=\"unit\"),\n",
    "           TableColumn(field='max', title=\"max\"),\n",
    "           TableColumn(field='p99', title=\"p99\"),\n",
    "           TableColumn(field='p95', title=\"p95\"),\n",
    "           TableColumn(field='p50', title=\"p50\"),\n",
    "           TableColumn(field='min', title=\"min\"),]\n",
    "table = DataTable(source=source, columns=columns, width=800, height=df2.shape[0]*30)\n",
    "    \n",
    "show(column( text1, text2, row(table)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def display_image(image_name):\n",
    "    files = glob.glob('/opt/ml/processing/outputs/profiler-reports/' + image_name)\n",
    "    for filename in files:\n",
    "        display(Image(filename=filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "report = load_report('OverallFrameworkMetrics')\n",
    "if 'Details' in report:\n",
    "    \n",
    "    display(Markdown(f\"\"\"## Framework metrics summary\"\"\"))\n",
    "    plots = []\n",
    "    text = ''\n",
    "    if 'phase' in report['Details']:\n",
    "        text = f\"\"\"The following piecharts show how much time your training job spent in \"training\", \"validation\" phase or \"others\".\n",
    "        Latter one is the accumulated time between steps, so when one step has finished but the new step has not started yet.\n",
    "        Ideally most time should be spent in training steps.\"\"\"\n",
    "\n",
    "        if 'others' in report['Details']['phase']:\n",
    "            others = float(report['Details']['phase']['others'])\n",
    "\n",
    "            if others > 25:\n",
    "                text = f\"\"\"{text} Your training job spent quite a significant amount of time ({round(others,2)}%) in phase \"others\".\n",
    "                You should check what is happening in between the steps.\"\"\"\n",
    "\n",
    "            plot = create_piechart(report['Details']['phase'], \n",
    "                                height=350,\n",
    "                                width=600,\n",
    "                                x1=0.2,\n",
    "                                x2=0.6,\n",
    "                                radius=0.3, \n",
    "                                title=\"Ratio between TRAIN/EVAL phase and others\")\n",
    "            plots.append(plot)\n",
    "\n",
    "    if 'forward_backward' in report['Details']:\n",
    "\n",
    "        event = max(report['Details']['forward_backward'], key=report['Details']['forward_backward'].get)\n",
    "        perc = report['Details']['forward_backward'][event]\n",
    "\n",
    "        text = f\"\"\"{text} The piechart on the right shows a more detailed breakdown. \n",
    "        It shows that {int(perc)}% of the time was spent in event {event}\"\"\"\n",
    "\n",
    "        if perc > 70:\n",
    "            text = f\"\"\"{text} The following piecharts shows that {int(perc)}% of your training \n",
    "            was spent in \"{event}\". There is quite a significant difference between the time spent in forward and backward\n",
    "            pass.\"\"\"\n",
    "        else:\n",
    "            text = f\"\"\"{text} The following piecharts shows that {int(perc)}% of your training \n",
    "            was spent in \"{event}\".\"\"\"\n",
    "\n",
    "        plot = create_piechart(report['Details']['forward_backward'], \n",
    "                            height=350,\n",
    "                            width=600,\n",
    "                            x1=0.2,\n",
    "                            x2=0.6,\n",
    "                            radius=0.3, \n",
    "                            title=\"Ratio between forward and backward pass\") \n",
    "        plots.append(plot)\n",
    "\n",
    "    if len(plots) > 0:\n",
    "        paragraph = Paragraph(text=text, width=1100)\n",
    "        show(column(paragraph, row(plots)))\n",
    "\n",
    "    plots = []\n",
    "    text=''\n",
    "    if 'ratio' in report['Details']:\n",
    "\n",
    "        key = list(report['Details']['ratio'].keys())[0]\n",
    "        ratio = report['Details']['ratio'][key]\n",
    "\n",
    "        text = f\"\"\"The following piechart shows a breakdown of the CPU/GPU operators. \n",
    "            It shows that {int(ratio)}% of the time was spent in executing operators on \"{key}\".\"\"\"\n",
    "\n",
    "        plot = create_piechart(report['Details']['ratio'], \n",
    "                                height=350,\n",
    "                                width=600,\n",
    "                                x1=0.2,\n",
    "                                x2=0.6,\n",
    "                                radius=0.3, \n",
    "                                title=\"Ratio between CPU/GPU operators\")\n",
    "        plots.append(plot)\n",
    "\n",
    "\n",
    "    if 'general' in report['Details']:\n",
    "        event = max(report['Details']['general'], key=report['Details']['general'].get)\n",
    "        perc = report['Details']['general'][event]\n",
    "        others = int(report['Details']['phase']['others'])\n",
    "\n",
    "        plot = create_piechart(report['Details']['general'], \n",
    "                            height=350,\n",
    "                            width=600,\n",
    "                            x1=0.2,\n",
    "                            x2=0.6,\n",
    "                            radius=0.3, \n",
    "                            title=\"General metrics recorded in framework \")\n",
    "        plots.append(plot)\n",
    "\n",
    "    if len(plots) > 0:\n",
    "        paragraph = Paragraph(text=text, width=1100)\n",
    "        show(column(paragraph, row(plots)))\n",
    "\n",
    "    plots = []\n",
    "    text = ''\n",
    "    if 'horovod' in report['Details']:\n",
    "        display(Markdown(f\"\"\"#### Overview: Horovod metrics\"\"\"))\n",
    "        event = max(report['Details']['horovod'], key=report['Details']['horovod'].get)\n",
    "        perc = report['Details']['horovod'][event]\n",
    "        text = f\"\"\"{text} The following piechart shows a detailed breakdown of the Horovod metrics that have been recorded\n",
    "        in your training job. The most expensive function was \"{event}\" with {int(perc)}%\"\"\"\n",
    "\n",
    "        plot = create_piechart(report['Details']['horovod'], \n",
    "                            height=350,\n",
    "                            width=600,\n",
    "                            x1=0.2,\n",
    "                            x2=0.6,\n",
    "                            radius=0.3, \n",
    "                            title=\"Horovod metrics \")\n",
    "\n",
    "        paragraph = Paragraph(text=text, width=1100)\n",
    "        show(column(paragraph, row(plot)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "rows = [] \n",
    "values = []\n",
    "if 'CPU_total' in report['Details']:\n",
    "    display(Markdown(f\"\"\"#### Overview: CPU operators\"\"\"))\n",
    "    event = max(report['Details']['CPU'], key=report['Details']['CPU'].get)\n",
    "    perc = report['Details']['CPU'][event]\n",
    "        \n",
    "    for function in report['Details']['CPU']:\n",
    "        percentage = round(report['Details']['CPU'][function],2)\n",
    "        time = report['Details']['CPU_total'][function]               \n",
    "        rows.append([percentage, time, function])\n",
    "\n",
    "    df = pd.DataFrame(rows) \n",
    "    df.columns = ['percentage', 'time', 'operator']\n",
    "    \n",
    "    df = df.sort_values(by=['percentage'], ascending=False)\n",
    "    source = ColumnDataSource(data=df)\n",
    "    columns = [TableColumn(field='percentage', title=\"Percentage\"),\n",
    "               TableColumn(field='time', title=\"Cumulative time\"),\n",
    "              TableColumn(field='operator', title=\"CPU operator\"),]\n",
    "\n",
    "    table = DataTable(source=source, columns=columns, width=550, height=350)\n",
    "\n",
    "    text = Paragraph(text=f\"\"\"The following table shows a list of operators that your training job run on CPU.\n",
    "    The most expensive operator on CPU was \"{event}\" with {int(perc)} %\"\"\")\n",
    "\n",
    "    plot = create_piechart(report['Details']['CPU'],\n",
    "                            height=350,\n",
    "                            width=600,\n",
    "                            x1=0.2,\n",
    "                            x2=0.6,\n",
    "                            radius=0.3, \n",
    "                           )\n",
    "\n",
    "    show(column(text, row(table, plot)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "rows = [] \n",
    "values = []\n",
    "if 'GPU_total' in report['Details']:\n",
    "    display(Markdown(f\"\"\"#### Overview: GPU operators\"\"\"))\n",
    "    event = max(report['Details']['GPU'], key=report['Details']['GPU'].get)\n",
    "    perc = report['Details']['GPU'][event]\n",
    "    \n",
    "    for function in report['Details']['GPU']:\n",
    "        percentage = round(report['Details']['GPU'][function],2)\n",
    "        time = report['Details']['GPU_total'][function]               \n",
    "        rows.append([percentage, time, function])\n",
    "\n",
    "    df = pd.DataFrame(rows) \n",
    "    df.columns = ['percentage', 'time', 'operator']\n",
    "    \n",
    "    df = df.sort_values(by=['percentage'], ascending=False)\n",
    "    source = ColumnDataSource(data=df)\n",
    "    columns = [TableColumn(field='percentage', title=\"Percentage\"),\n",
    "               TableColumn(field='time', title=\"Cumulative time\"),\n",
    "              TableColumn(field='operator', title=\"GPU operator\"),]\n",
    "    table = DataTable(source=source, columns=columns, width=450, height=350)\n",
    "\n",
    "    text = Paragraph(text=f\"\"\"The following table shows a list of operators that your training job run on GPU.\n",
    "    The most expensive operator on GPU was \"{event}\" with {int(perc)} %\"\"\")\n",
    "\n",
    "    plot = create_piechart(report['Details']['GPU'],\n",
    "                            height=350,\n",
    "                            width=600,\n",
    "                            x1=0.2,\n",
    "                            x2=0.6,\n",
    "                            radius=0.3, \n",
    "                           )\n",
    "\n",
    "    show(column(text, row(table, plot)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "description = {}\n",
    "description['CPUBottleneck'] = 'Checks if CPU usage is high but GPU usage is low at the same time, it may indicate a CPU bottleneck where GPU is waiting for data to arrive from CPU. The rule triggers if number of CPU bottlenecks exceeds a predefined threshold.'\n",
    "description['IOBottleneck'] = 'If IO wait time is high but at the same time GPU usage is low, it may indicate an IO bottleneck where GPU is waiting for data to arrive from disk. The rule triggers if number of IO bottlenecks exceeds a predefined threshold.'\n",
    "#description['Dataloaders'] = 'Checks how many data-loader processes are running in parallel and whether the total number is equal the number of available CPU cores. The rule triggers if number is much smaller or larger than the number of available cores. If too small, it may lead to low GPU utilization. If too large it may lead to too many context switches on CPU.'\n",
    "description['GPUMemoryIncrease'] = 'If model and/or batch size is too large then training will run out of memory and crash.'\n",
    "description['BatchSize'] = 'Checks if GPU is under-utilized because of the batch size being too small. To detect this the rule analyzes the average GPU memory footprint, CPU and GPU utilization. '\n",
    "description['LowGPUUtilization'] = 'Checks if GPU utilization is low or suffers from fluctuations. This can happen if there are bottlenecks, many blocking calls due to synchronizations or batch size too small.'\n",
    "description['MaxInitializationTime'] = 'Checks if the training initialization is taking too much time. The rule waits until first step is available. This can happen if you are running in File mode and a lot of data needs to be downloaded from Amazon S3.'\n",
    "description['LoadBalancing'] = 'Detect issues in workload balancing between multiple GPUs. Workload imbalance can for instance occur in data parallel training when gradients are accumulated on primary GPU so this GPU will be overused with regards to other GPUs limiting the effect of parallelization.  '\n",
    "description['StepOutlier'] = 'Detect outliers in step duration. Time for forward and backward pass should be roughly the same throughout the training. If there are significant outliers it would indicate an issue due to a system stall or a bottleneck.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "recommendation = {}\n",
    "recommendation['CPUBottleneck'] = 'CPU bottlenecks can happen when data preprocessing is very compute intensive. You should consider increasing the number of data-loader processes or apply pre-fetching.'\n",
    "recommendation['IOBottleneck'] = 'Pre-fetch data or choose different file formats such as binary formats which improves read performance.'\n",
    "#recommendation['Dataloaders'] = 'Increase or decrease the number of data-loader processes'\n",
    "recommendation['GPUMemoryIncrease'] = 'Choose a larger instance type with more memory (if it is not a memory leak) or apply model parallelism (Rubik)'\n",
    "recommendation['BatchSize'] = 'Run on a smaller instance type or increase batch size'\n",
    "recommendation['LowGPUUtilization'] = 'Check for bottlenecks, minimize blocking calls, change distributed training strategy, increase batch-size.'\n",
    "recommendation['MaxInitializationTime'] = 'Switch from File to Pipe mode'\n",
    "recommendation['LoadBalancing'] = 'Choose different distributed training strategy or different distributed training framework'\n",
    "recommendation['StepOutlier'] = 'Check for bottlenecks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "files = glob.glob('/opt/ml/processing/outputs/profiler-reports/*json')\n",
    "summary = {}\n",
    "for i in files:\n",
    "    rule_name = i.split('/')[-1].replace('.json','')\n",
    "    if rule_name == \"OverallSystemUsage\" or rule_name == \"OverallFrameworkMetrics\":\n",
    "        continue\n",
    "    rule_report = json.load(open(i))\n",
    "    summary[rule_name] = {}\n",
    "    summary[rule_name]['Description'] = description[rule_name]\n",
    "    summary[rule_name]['Recommendation'] = recommendation[rule_name]\n",
    "    summary[rule_name]['Number of times rule triggered'] = rule_report['RuleTriggered'] \n",
    "    #summary[rule_name]['Number of violations'] = rule_report['Violations'] \n",
    "    summary[rule_name]['Number of datapoints'] = rule_report['Datapoints']\n",
    "    summary[rule_name]['Rule parameters'] = rule_report['RuleParameters']\n",
    "\n",
    "df = pd.DataFrame.from_dict(summary, orient='index')\n",
    "df = df.sort_values(by=['Number of times rule triggered'], ascending=False)\n",
    "\n",
    "display(Markdown(f\"\"\"The following table shows a summary of the executed profiler rules. \n",
    "The table is sorted by the rules that triggered most frequently. In your training job this was the case\n",
    "for rule {df.index[0]}. It has processed {df.values[0,3]} datapoints and triggered {df.values[0,2]} times.\"\"\"))\n",
    "with pd.option_context('display.colheader_justify','left'):    \n",
    "    pretty_print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "analyse_phase = \"training\"\n",
    "if job_statistics and \"initialization_in_seconds\" in job_statistics:\n",
    "    if job_statistics[\"initialization_in_seconds\"] > job_statistics[\"training_loop_duration_in_seconds\"]:\n",
    "        analyse_phase = \"initialization\"\n",
    "        time = job_statistics[\"initialization_in_seconds\"]\n",
    "        perc = job_statistics[\"initialization_%\"]\n",
    "        display(Markdown(f\"\"\"The initialization phase lasted for {int(time)} seconds which is {int(perc)}%*\n",
    "        of the training job time. Since the training loop has taken the most time, \n",
    "        we dive deep into the events occurring during this phase\"\"\"))\n",
    "        display(Markdown(\"\"\"### Analyzing initialization\\n\\n\"\"\"))\n",
    "    time = job_statistics[\"training_loop_duration_in_seconds\"]\n",
    "    perc = job_statistics[\"training_loop_%\"]\n",
    "    display(Markdown(f\"\"\"The training loop lasted for {int(time)} seconds which is {int(perc)}% of the training job time.\n",
    "                    Since the training loop has taken the most time, we dive deep into the events occurring during this phase\"\"\"))\n",
    "if analyse_phase == 'training':\n",
    "    display(Markdown(\"\"\"### Analyzing the training loop\\n\\n\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "if analyse_phase == \"initialization\":\n",
    "    display(Markdown(\"\"\"### MaxInitializationTime\\n\\nThis rule helps to detect if the training initialization is taking too much time. \\nThe rule waits until first step is available. The rule takes the parameter `threshold` that defines how many minutes to wait for the first step to become available. Default is 20 minutes.\\nYou can run the rule locally in the following way:\n",
    "    \"\"\"))\n",
    "    \n",
    "    _ = load_report(\"MaxInitializationTime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "if analyse_phase == \"training\":\n",
    "    display(Markdown(\"\"\"#### Step duration analysis\"\"\"))\n",
    "    report = load_report('StepOutlier')\n",
    "    parameters = report['RuleParameters']\n",
    "    params = report['RuleParameters'].split('\\n')\n",
    "    stddev = params[3].split(':')[1]\n",
    "    mode = params[1].split(':')[1]\n",
    "    n_outlier = params[2].split(':')[1]\n",
    "    display(Markdown(f\"\"\"The StepOutlier rule measures step durations and checks for outliers.\\nThe rule \\\n",
    "    returns `True` if duration is larger than {stddev} times the standard deviation. The rule \\\n",
    "    also takes the parameter `mode`, that specifies whether steps from training or validation phase \\\n",
    "    should be checked. In your processing job `mode` was specified as {mode}. \\\n",
    "    Typically the first step is taking significantly more time and to avoid the \\\n",
    "    rule triggering immediately, one can use `n_outliers` to specify the number of outliers to ignore. \\\n",
    "    `n_outliers` was set to {n_outlier}.\\n \n",
    "    \"\"\"))\n",
    "\n",
    "    if report and len(report['Details']['step_details']) > 0:\n",
    "        for node_id in report['Details']['step_details']:\n",
    "            tmp = report['RuleParameters'].split('threshold:')\n",
    "            threshold = tmp[1].split('\\n')[0]\n",
    "            n_outliers = report['Details']['step_details'][node_id]['number_of_outliers']\n",
    "            mean = report['Details']['step_details'][node_id]['step_stats']['mean']\n",
    "            stddev = report['Details']['step_details'][node_id]['stddev']\n",
    "            phase = report['Details']['step_details'][node_id]['phase']\n",
    "            display(Markdown(f\"\"\"**Step durations on node {node_id}:**\"\"\"))\n",
    "            display(Markdown(f\"\"\"The following table is a summary of the statistics of step durations measured on node {node_id}.\n",
    "            The rule has analyzed the step duration from {phase} phase.\n",
    "            The average step duration on node {node_id} was {round(mean, 2)}s. \n",
    "            The rule detected {n_outliers} outliers, where step duration was larger than {threshold} times the standard deviation of {stddev}s\n",
    "                             \\n\"\"\"))\n",
    "            step_stats_df = pd.DataFrame.from_dict(report['Details']['step_details'][node_id]['step_stats'], orient='index').T\n",
    "            step_stats_df.index = ['Step Durations in [s]']\n",
    "            pretty_print(step_stats_df)\n",
    "        \n",
    "        display(Markdown(f\"\"\"The following histogram shows the step durations measured on the different nodes. \n",
    "            You can enable/disable the visualization of a histogram by clicking on the label in the legend.\"\"\"))\n",
    "\n",
    "        plot = figure(plot_height=450, \n",
    "                          plot_width=850, \n",
    "                          x_range=(-1,100),\n",
    "                          title=f\"\"\"Step durations\"\"\")  \n",
    "        \n",
    "        colors = bokeh.palettes.viridis(len(report['Details']['step_details']))\n",
    "        \n",
    "        for index, node_id in enumerate(report['Details']['step_details']):\n",
    "            probs = report['Details']['step_details'][node_id]['probs']\n",
    "            binedges = report['Details']['step_details'][node_id]['binedges']\n",
    "           \n",
    "            plot.quad( top=probs,\n",
    "                    bottom=0,\n",
    "                    left=np.arange(0,98,2),\n",
    "                    right=np.arange(2,100,2),\n",
    "                    line_color=\"white\",\n",
    "                    fill_color=colors[index],\n",
    "                    fill_alpha=0.7,\n",
    "                    legend=node_id)\n",
    "            \n",
    "        plot.add_layout(Legend(), 'right')    \n",
    "        plot.y_range.start = 0\n",
    "        plot.xaxis.axis_label = f\"\"\"Utilization\"\"\"\n",
    "        plot.yaxis.axis_label = \"Occurrences\"\n",
    "        plot.grid.grid_line_color = \"white\"\n",
    "        plot.legend.click_policy=\"hide\"\n",
    "        plot.legend.location = 'center_right'\n",
    "        show(plot)\n",
    "        \n",
    "    if report['RuleTriggered'] > 0:\n",
    "                        \n",
    "        text=f\"\"\"To get a better understanding of what may have caused those outliers,\n",
    "        we correlate the timestamps of step outliers with other framework metrics that happened at the same time.\n",
    "        The left chart shows how much time was spent in the different framework\n",
    "        metrics aggregated by event phase. The chart on the right shows the histogram of normal step durations (without\n",
    "        outliers). The following chart shows how much time was spent in the different \n",
    "        framework metrics when step outliers occurred. In this chart framework metrics are not aggregated by event phase.\"\"\"\n",
    "        \n",
    "        if 'phase' in report['Details']:\n",
    "            text = f\"\"\"{text} The chart (in the middle) shows whether step outliers mainly happened during CPU bottlenecks\n",
    "            \"\"\"\n",
    "\n",
    "            plot = create_piechart(report['Details']['phase'], \n",
    "                                height=350,\n",
    "                                width=600,\n",
    "                                x1=0.2,\n",
    "                                x2=0.6,\n",
    "                                radius=0.3, \n",
    "                                title=\"Ratio between TRAIN/EVAL phase and others\")\n",
    "            plots.append(plot)\n",
    "\n",
    "            if 'forward_backward' in report['Details'] and  len(report['Details']['forward_backward']) > 0:\n",
    "\n",
    "                event = max(report['Details']['forward_backward'], key=report['Details']['forward_backward'].get)\n",
    "                perc = report['Details']['forward_backward'][event]\n",
    "\n",
    "                text = f\"\"\"{text} The piecharts on the right shows a more detailed breakdown. \n",
    "                It shows that {int(perc)}% of the time was spent in event {event}\"\"\"\n",
    "\n",
    "                plot = create_piechart(report['Details']['forward_backward'], \n",
    "                                    height=350,\n",
    "                                    width=600,\n",
    "                                    x1=0.2,\n",
    "                                    x2=0.6,\n",
    "                                    radius=0.3, \n",
    "                                    title=\"Ratio between forward and backward pass\") \n",
    "                plots.append(plot)\n",
    "\n",
    "            if len(plots) > 0:\n",
    "                paragraph = Paragraph(text=text, width=900)\n",
    "                show(column(paragraph, row(plots)))\n",
    "\n",
    "            plots = []\n",
    "            text = \"\"\n",
    "            if 'ratio' in report['Details'] and len(report['Details']['ratio']) > 0:\n",
    "\n",
    "                key = list(report['Details']['ratio'].keys())[0]\n",
    "                ratio = report['Details']['ratio'][key]\n",
    "\n",
    "                text = f\"\"\"The following piechart shows a breakdown of the CPU/GPU operators that happened during step outliers. \n",
    "                    It shows that {int(ratio)}% of the time was spent in executing operators in {key}.\"\"\"\n",
    "\n",
    "                plot = create_piechart(report['Details']['ratio'], \n",
    "                                        height=350,\n",
    "                                        width=600,\n",
    "                                        x1=0.2,\n",
    "                                        x2=0.6,\n",
    "                                        radius=0.3, \n",
    "                                        title=\"Ratio between CPU/GPU operators\")\n",
    "                plots.append(plot)\n",
    "\n",
    "\n",
    "            if 'general' in report['Details'] and len(report['Details']['general']) > 0:\n",
    "\n",
    "                event = max(report['Details']['general'], key=report['Details']['general'].get)\n",
    "                perc = report['Details']['general'][event]\n",
    "\n",
    "                plot = create_piechart(report['Details']['general'], \n",
    "                                    height=350,\n",
    "                                    width=600,\n",
    "                                    x1=0.2,\n",
    "                                    x2=0.6,\n",
    "                                    radius=0.3, \n",
    "                                    title=\"General metrics recorded in framework \")\n",
    "                plots.append(plot)\n",
    "\n",
    "            if len(plots) > 0:\n",
    "                paragraph = Paragraph(text=text, width=900)\n",
    "                show(column(paragraph, row(plots)))\n",
    "\n",
    "            plots = []\n",
    "            text = \"\"\n",
    "            if 'horovod' in report['Details'] and len(report['Details']['horovod']) > 0:\n",
    "\n",
    "                event = max(report['Details']['horovod'], key=report['Details']['horovod'].get)\n",
    "                perc = report['Details']['horovod'][event]\n",
    "                text = f\"\"\"The following piechart shows a detailed breakdown of the Horovod metrics that have been\n",
    "                recorded when step outliers happened. The most expensive function was {event} with {int(perc)}%\"\"\"\n",
    "\n",
    "                plot = create_piechart(report['Details']['horovod'], \n",
    "                                    height=350,\n",
    "                                    width=600,\n",
    "                                    x1=0.2,\n",
    "                                    x2=0.6,\n",
    "                                    radius=0.3, \n",
    "                                    title=\"General metrics recorded in framework \")\n",
    "\n",
    "                paragraph = Paragraph(text=text, width=900)\n",
    "                show(column(paragraph, row(plot)))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "if analyse_phase == \"training\":\n",
    "    display(Markdown(\"\"\"#### GPU utilization analysis\\n\\n\"\"\"))\n",
    "    report = load_report('LowGPUUtilization')\n",
    "    if report:\n",
    "        params = report['RuleParameters'].split('\\n')\n",
    "        threshold_p95 = params[0].split(':')[1]\n",
    "        threshold_p5 = params[1].split(':')[1]\n",
    "        window = params[2].split(':')[1]\n",
    "        patience = params[3].split(':')[1]\n",
    "        violations = report['Violations']\n",
    "        text=Paragraph(text=f\"\"\"The LowGPUUtilization rule checks for low and fluctuating GPU usage.If usage is \n",
    "        consistently low, it might be caused by bottlenecks or if batch size/model is too small.If usage is heavily \n",
    "        fluctuating it can be caused by bottlenecks or blocking calls. The rule computed the 95th and 5th \n",
    "        quantile of GPU utilization on {window} continuous datapoints and found {violations} cases where \n",
    "        p95 was above {threshold_p95}% and p5 was below {threshold_p5}%. If p95 is high and p5 is low it would indicate that the \n",
    "        usage is highly fluctuating. If both values are very low it would mean that the machine \n",
    "        is under-utilized. During initialization utilization is likely 0, so the rule skipped the first {patience} datapoints.\n",
    "        \"\"\", width=800)\n",
    "        show(text)\n",
    "\n",
    "        \n",
    "        if len(report['Details']) > 0:\n",
    "            \n",
    "            timestamp = us_since_epoch_to_human_readable_time(report['Details']['last_timestamp'])\n",
    "            date = datetime.datetime.strptime(timestamp, '%Y-%m-%dT%H:%M:%S:%f')\n",
    "            day = date.date().strftime(\"%m/%d/%Y\")\n",
    "            hour = date.time().strftime(\"%H:%M:%S\")\n",
    "            text = Paragraph(text=f\"\"\"Your training job is under-utilizing the instance. You may want to consider\n",
    "            to either switch to a smaller instance type. \n",
    "            The last time the LowGPUUtilization rule triggered in your training job was on {day} at {hour}.\n",
    "            The following boxplots are a snapshot from this timestamp that show for each node the total \n",
    "            CPU utilization and the utilization and memory usage per GPU (without outliers).\"\"\", width=800)\n",
    "            show(text)\n",
    "            \n",
    "            del report['Details']['last_timestamp']\n",
    "            \n",
    "            for node_id in report['Details']:\n",
    "                \n",
    "                plot = figure(plot_height=350, \n",
    "                          plot_width=1000,\n",
    "                          toolbar_location='right',\n",
    "                          tools=\"hover,wheel_zoom,reset,pan\", \n",
    "                          title=f\"Node {node_id}\",\n",
    "                          x_range=(0,17),\n",
    "                          )\n",
    "               \n",
    "                for index, key in enumerate(report['Details'][node_id]):\n",
    "                    display(Markdown(f\"\"\"**GPU utilization of {key} on node {node_id}:**\"\"\"))\n",
    "                    text = \"\"\n",
    "                    gpu_max = report['Details'][node_id][key]['gpu_max']\n",
    "                    p_95 = report['Details'][node_id][key]['gpu_95']\n",
    "                    p_5 = report['Details'][node_id][key]['gpu_5']\n",
    "                    text = f\"\"\"{text} The max utilization of {key} on node {node_id} was {gpu_max}%\"\"\"\n",
    "                    if p_95 < int(threshold_p95): \n",
    "                        text = f\"\"\"{text} and the 95th percentile was only {p_95}%. \n",
    "                        {key} on node {node_id} is under-utilized\"\"\"\n",
    "                    if p_5 < int(threshold_p5): \n",
    "                        text = f\"\"\"{text} and the 5th percentile was only {p_5}%\"\"\"\n",
    "                    if p_95 - p_5 > 50:\n",
    "                        text = f\"\"\"{text} The difference between 5th quantile {p_5}% and 95th quantile {p_95}% is quite \n",
    "                        significant, which means that utilization on {key} is fluctuating quite a lot.\\n\"\"\"\n",
    "     \n",
    "                    upper = report['Details'][node_id][key]['upper']\n",
    "                    lower = report['Details'][node_id][key]['lower']\n",
    "                    p75 = report['Details'][node_id][key]['p75']\n",
    "                    p25 = report['Details'][node_id][key]['p25']\n",
    "                    p50 = report['Details'][node_id][key]['p50']\n",
    "\n",
    "                    plot.segment(index+1, upper, index+1, p75, line_color=\"black\")\n",
    "                    plot.segment(index+1, lower, index+1, p25, line_color=\"black\")\n",
    "\n",
    "                    plot.vbar(index+1, 0.7, p50, p75, fill_color=\"#FDE725\", line_color=\"black\")\n",
    "                    plot.vbar(index+1, 0.7, p25, p50, fill_color=\"#440154\", line_color=\"black\")\n",
    "\n",
    "                    plot.rect(index+1, lower, 0.2, 0.01, line_color=\"black\")\n",
    "                    plot.rect(index+1, upper, 0.2, 0.01, line_color=\"black\")\n",
    "\n",
    "                    plot.xaxis.major_label_overrides[index+1] = key\n",
    "                    plot.xgrid.grid_line_color = None\n",
    "                    plot.ygrid.grid_line_color = \"white\"\n",
    "                    plot.grid.grid_line_width = 0\n",
    "\n",
    "                    plot.xaxis.major_label_text_font_size=\"10px\"\n",
    "                    text=Paragraph(text=f\"\"\"{text}\"\"\", width=900)\n",
    "                    show(text)\n",
    "                plot.xaxis.ticker = np.arange(index+2)\n",
    "                \n",
    "                show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "if analyse_phase == \"training\":\n",
    "    display(Markdown(\"\"\" #### Batch size\"\"\"))\n",
    "    report = load_report('BatchSize')\n",
    "    if report:\n",
    "        params = report['RuleParameters'].split('\\n')\n",
    "        cpu_threshold_p95 = int(params[0].split(':')[1])\n",
    "        gpu_threshold_p95 = int(params[1].split(':')[1])\n",
    "        gpu_memory_threshold_p95 = int(params[2].split(':')[1])\n",
    "        patience = int(params[3].split(':')[1])\n",
    "        window = int(params[4].split(':')[1])\n",
    "        violations = report['Violations']\n",
    "        \n",
    "        text = Paragraph(text=f\"\"\"The BatchSize rule helps to detect if GPU is under-utilized because of the batch size being \n",
    "        too small. To detect this the rule analyzes the GPU memory footprint, CPU and GPU utilization. The rule checked if the 95th quantile of CPU utilization is below cpu_threshold_p95 of \n",
    "        {cpu_threshold_p95}%, the 95th quantile of GPU utilization is below gpu_threshold_p95 of {gpu_threshold_p95}% and the 95th quantile of memory footprint \\\n",
    "        below gpu_memory_threshold_p95 of {gpu_memory_threshold_p95}%. In your training job this happened {violations} times. \\\n",
    "        The rule skipped the first {patience} datapoints. The rule computed the quantiles over window size of {window} continuous datapoints.\\n\n",
    "        \"\"\", width=800)\n",
    "        show(text)\n",
    "        if len(report['Details']) >0: \n",
    "            timestamp = us_since_epoch_to_human_readable_time(report['Details']['last_timestamp'])\n",
    "            date = datetime.datetime.strptime(timestamp, '%Y-%m-%dT%H:%M:%S:%f')\n",
    "            day = date.date().strftime(\"%m/%d/%Y\")\n",
    "            hour = date.time().strftime(\"%H:%M:%S\")\n",
    "            del report['Details']['last_timestamp']\n",
    "            text = Paragraph(text=f\"\"\"Your training job is under-utilizing the instance. You may want to consider\n",
    "            to either switch to a smaller instance type or to increase batch size of your model training. \n",
    "            The last time the BatchSize rule triggered in your training job was on {day} at {hour}.\n",
    "            The following boxplots are a snapshot from this timestamp that show for each node the total \n",
    "            CPU utilization and the utilization and memory usage per GPU.\"\"\", \n",
    "            width=800)\n",
    "            show(text)\n",
    "\n",
    "            for node_id in report['Details']:\n",
    "                xmax = max(20, len(report['Details'][node_id]))\n",
    "                \n",
    "                plot = figure(plot_height=350, \n",
    "                          plot_width=1000,\n",
    "                          toolbar_location='right',\n",
    "                          tools=\"hover,wheel_zoom,reset,pan\", \n",
    "                          title=f\"Node {node_id}\",\n",
    "                          x_range=(0,xmax)\n",
    "                          )\n",
    "                \n",
    "                for index, key in enumerate(report['Details'][node_id]):\n",
    "                        upper = report['Details'][node_id][key]['upper']\n",
    "                        lower = report['Details'][node_id][key]['lower']\n",
    "                        p75 = report['Details'][node_id][key]['p75']\n",
    "                        p25 = report['Details'][node_id][key]['p25']\n",
    "                        p50 = report['Details'][node_id][key]['p50']\n",
    "\n",
    "                        plot.segment(index+1, upper, index+1, p75, line_color=\"black\")\n",
    "                        plot.segment(index+1, lower, index+1, p25, line_color=\"black\")\n",
    "\n",
    "                        plot.vbar(index+1, 0.7, p50, p75, fill_color=\"#FDE725\", line_color=\"black\")\n",
    "                        plot.vbar(index+1, 0.7, p25, p50, fill_color=\"#440154\", line_color=\"black\")\n",
    "\n",
    "                        plot.rect(index+1, lower, 0.2, 0.01, line_color=\"black\")\n",
    "                        plot.rect(index+1, upper, 0.2, 0.01, line_color=\"black\")\n",
    "\n",
    "                        plot.xaxis.major_label_overrides[index+1] = key\n",
    "                        plot.xgrid.grid_line_color = None\n",
    "                        plot.ygrid.grid_line_color = \"white\"\n",
    "                        plot.grid.grid_line_width = 0\n",
    "\n",
    "                        plot.xaxis.major_label_text_font_size=\"10px\"\n",
    "                plot.xaxis.ticker = np.arange(index+2)\n",
    "\n",
    "                show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "if analyse_phase == \"training\": \n",
    "    display(Markdown(\"\"\"#### CPU bottlenecks\\n\\n\"\"\"))\n",
    "\n",
    "    report = load_report('CPUBottleneck')\n",
    "    if report:\n",
    "        params = report['RuleParameters'].split('\\n')\n",
    "        threshold = int(params[0].split(':')[1])\n",
    "        cpu_threshold = int(params[1].split(':')[1])\n",
    "        gpu_threshold = int(params[2].split(':')[1])\n",
    "        patience = int(params[3].split(':')[1])\n",
    "        datapoints = report['Datapoints']\n",
    "        violations = report['Violations']\n",
    "        if report['Violations'] > 0:\n",
    "            perc = int(report['Violations']/report['Datapoints']*100)\n",
    "        else:\n",
    "            perc = 0\n",
    "        if perc < threshold:\n",
    "            string = 'below'\n",
    "        else:\n",
    "            string = 'above'\n",
    "        text = f\"\"\"The CPUBottleneck rule checked when CPU utilization was above cpu_threshold of {cpu_threshold}% \n",
    "        and GPU utilization was below gpu_threshold of {gpu_threshold}%. \n",
    "        During initialization utilization is likely 0, so the rule skipped the first {patience} datapoints.\n",
    "        With this configuration the rule found {violations} CPU bottlenecks which is {perc}% of the total time. This is {string} the threshold of {threshold}%\"\"\"\n",
    "\n",
    "\n",
    "        if report:\n",
    "\n",
    "            plots = []\n",
    "            text = \"\"\n",
    "            if report['RuleTriggered'] > 0:\n",
    "\n",
    "                low_gpu = report['Details']['low_gpu_utilization']\n",
    "                cpu_bottleneck = {}\n",
    "                cpu_bottleneck[\"GPU usage above threshold\"] = report[\"Datapoints\"] - report[\"Details\"][\"low_gpu_utilization\"]\n",
    "                cpu_bottleneck[\"GPU usage below threshold\"] = report[\"Details\"][\"low_gpu_utilization\"] - len(report[\"Details\"])\n",
    "                cpu_bottleneck[\"Low GPU usage due to CPU bottlenecks\"] = len(report[\"Details\"])\n",
    "\n",
    "                n_bottlenecks = round(len(report['Details']['bottlenecks'])/datapoints * 100, 2)\n",
    "                text = f\"\"\"The following chart (left) shows how many datapoints were below the gpu_threshold of {gpu_threshold}%\n",
    "                and how many of those datapoints were likely caused by a CPU bottleneck. The rule found {low_gpu} out of {datapoints} datapoints which had a GPU utilization \n",
    "                below {gpu_threshold}%. Out of those datapoints {n_bottlenecks}% were likely caused by CPU bottlenecks. \n",
    "                \"\"\"\n",
    "\n",
    "                plot = create_piechart(cpu_bottleneck, \n",
    "                                    height=350,\n",
    "                                    width=600,\n",
    "                                    x1=0.2,\n",
    "                                    x2=0.6,\n",
    "                                    radius=0.3, \n",
    "                                    title=\"Low GPU usage caused by CPU bottlenecks\")\n",
    "\n",
    "                plots.append(plot)\n",
    "\n",
    "                if 'phase' in report['Details']:\n",
    "                    text = f\"\"\"{text} The chart (in the middle) shows whether CPU bottlenecks mainly happened during CPU bottlenecks\n",
    "                    \"\"\"\n",
    "\n",
    "                    plot = create_piechart(report['Details']['phase'], \n",
    "                                        height=350,\n",
    "                                        width=600,\n",
    "                                        x1=0.2,\n",
    "                                        x2=0.6,\n",
    "                                        radius=0.3, \n",
    "                                        title=\"Ratio between TRAIN/EVAL phase and others\")\n",
    "                    plots.append(plot)\n",
    "\n",
    "                if 'forward_backward' in report['Details'] and  len(report['Details']['forward_backward']) > 0:\n",
    "\n",
    "                    event = max(report['Details']['forward_backward'], key=report['Details']['forward_backward'].get)\n",
    "                    perc = report['Details']['forward_backward'][event]\n",
    "\n",
    "                    text = f\"\"\"{text} The piecharts on the right shows a more detailed breakdown. \n",
    "                    It shows that {int(perc)}% of the time was spent in event {event}\"\"\"\n",
    "\n",
    "                    plot = create_piechart(report['Details']['forward_backward'], \n",
    "                                        height=350,\n",
    "                                        width=600,\n",
    "                                        x1=0.2,\n",
    "                                        x2=0.6,\n",
    "                                        radius=0.3, \n",
    "                                        title=\"Ratio between forward and backward pass\") \n",
    "                    plots.append(plot)\n",
    "\n",
    "                if len(plots) > 0:\n",
    "                    paragraph = Paragraph(text=text, width=900)\n",
    "                    show(column(paragraph, row(plots)))\n",
    "\n",
    "                plots = []\n",
    "                text = \"\"\n",
    "                if 'ratio' in report['Details'] and len(report['Details']['ratio']) > 0:\n",
    "\n",
    "                    key = list(report['Details']['ratio'].keys())[0]\n",
    "                    ratio = report['Details']['ratio'][key]\n",
    "\n",
    "                    text = f\"\"\"The following piechart shows a breakdown of the CPU/GPU operators that happened during CPU bottlenecks. \n",
    "                        It shows that {int(ratio)}% of the time was spent in executing operators in {key}.\"\"\"\n",
    "\n",
    "                    plot = create_piechart(report['Details']['ratio'], \n",
    "                                            height=350,\n",
    "                                            width=600,\n",
    "                                            x1=0.2,\n",
    "                                            x2=0.6,\n",
    "                                            radius=0.3, \n",
    "                                            title=\"Ratio between CPU/GPU operators\")\n",
    "                    plots.append(plot)\n",
    "\n",
    "\n",
    "                if 'general' in report['Details'] and len(report['Details']['general']) > 0:\n",
    "\n",
    "                    event = max(report['Details']['general'], key=report['Details']['general'].get)\n",
    "                    perc = report['Details']['general'][event]\n",
    "\n",
    "                    plot = create_piechart(report['Details']['general'], \n",
    "                                        height=350,\n",
    "                                        width=600,\n",
    "                                        x1=0.2,\n",
    "                                        x2=0.6,\n",
    "                                        radius=0.3, \n",
    "                                        title=\"General metrics recorded in framework \")\n",
    "                    plots.append(plot)\n",
    "\n",
    "                if len(plots) > 0:\n",
    "                    paragraph = Paragraph(text=text, width=900)\n",
    "                    show(column(paragraph, row(plots)))\n",
    "\n",
    "                plots = []\n",
    "                text = \"\"\n",
    "                if 'horovod' in report['Details'] and len(report['Details']['horovod']) > 0:\n",
    "\n",
    "                    event = max(report['Details']['horovod'], key=report['Details']['horovod'].get)\n",
    "                    perc = report['Details']['horovod'][event]\n",
    "                    text = f\"\"\"The following piechart shows a detailed breakdown of the Horovod metrics that have been\n",
    "                    recorded when CPU bottleneck happened. The most expensive function was {event} with {int(perc)}%\"\"\"\n",
    "\n",
    "                    plot = create_piechart(report['Details']['horovod'], \n",
    "                                        height=350,\n",
    "                                        width=600,\n",
    "                                        x1=0.2,\n",
    "                                        x2=0.6,\n",
    "                                        radius=0.3, \n",
    "                                        title=\"General metrics recorded in framework \")\n",
    "\n",
    "                    paragraph = Paragraph(text=text, width=900)\n",
    "                    show(column(paragraph, row(plot)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "if analyse_phase == \"training\": \n",
    "    display(Markdown(\"\"\"#### I/O bottlenecks\\n\\n\"\"\"))\n",
    "\n",
    "    report = load_report('IOBottleneck')\n",
    "    if report:\n",
    "        params = report['RuleParameters'].split('\\n')\n",
    "        threshold = int(params[0].split(':')[1])\n",
    "        io_threshold = int(params[1].split(':')[1])\n",
    "        gpu_threshold = int(params[2].split(':')[1])\n",
    "        patience = int(params[3].split(':')[1])\n",
    "        violations = report['Violations']\n",
    "        if report['Violations'] > 0:\n",
    "            perc = int(report['Violations']/report['Datapoints']*100)\n",
    "        else:\n",
    "            perc = 0\n",
    "        if perc < threshold:\n",
    "            string = 'below'\n",
    "        else:\n",
    "            string = 'above'\n",
    "        text = f\"\"\"The IOBottleneck rule checked when I/O wait time was above io_threshold of {io_threshold}% \n",
    "        and GPU utilization was below gpu_threshold of {gpu_threshold}. During initialization utilization is likely 0, so the rule skipped the first {patience} datapoints. \n",
    "        With this configuration the rule found {violations} I/O bottlenecks which is {perc}% of the total time. This is {string} the threshold of {threshold}%\"\"\"\n",
    "\n",
    "        if report:\n",
    "\n",
    "            plots = []\n",
    "            text = \"\"\n",
    "            if report['RuleTriggered'] > 0:\n",
    "\n",
    "                low_gpu = report['Details']['low_gpu_utilization']\n",
    "                cpu_bottleneck = {}\n",
    "                cpu_bottleneck[\"GPU usage above threshold\"] = report[\"Datapoints\"] - report[\"Details\"][\"low_gpu_utilization\"]\n",
    "                cpu_bottleneck[\"GPU usage below threshold\"] = report[\"Details\"][\"low_gpu_utilization\"] - len(report[\"Details\"])\n",
    "                cpu_bottleneck[\"Low GPU usage due to I/O bottlenecks\"] = len(report[\"Details\"])\n",
    "\n",
    "                n_bottlenecks = round(len(report['Details']['bottlenecks'])/datapoints * 100, 2)\n",
    "                text = f\"\"\"The following chart (left) shows how many datapoints were below the gpu_threshold of {gpu_threshold}%\n",
    "                and how many of those datapoints were likely caused by a I/O bottleneck. The rule found {low_gpu} out of {datapoints} datapoints which had a GPU utilization \n",
    "                below {gpu_threshold}%. Out of those datapoints {n_bottlenecks}% were likely caused by I/O bottlenecks. \n",
    "                \"\"\"\n",
    "\n",
    "                plot = create_piechart(cpu_bottleneck, \n",
    "                                    height=350,\n",
    "                                    width=600,\n",
    "                                    x1=0.2,\n",
    "                                    x2=0.6,\n",
    "                                    radius=0.3, \n",
    "                                    title=\"Low GPU usage caused by I/O bottlenecks\")\n",
    "\n",
    "                plots.append(plot)\n",
    "\n",
    "                if 'phase' in report['Details']:\n",
    "                    text = f\"\"\"{text} The chart (in the middle) shows whether I/O bottlenecks mainly happened during  trianing or validation phase.\n",
    "                    \"\"\"\n",
    "\n",
    "                    plot = create_piechart(report['Details']['phase'], \n",
    "                                        height=350,\n",
    "                                        width=600,\n",
    "                                        x1=0.2,\n",
    "                                        x2=0.6,\n",
    "                                        radius=0.3, \n",
    "                                        title=\"Ratio between TRAIN/EVAL phase and others\")\n",
    "                    plots.append(plot)\n",
    "\n",
    "                if 'forward_backward' in report['Details'] and  len(report['Details']['forward_backward']) > 0:\n",
    "\n",
    "                    event = max(report['Details']['forward_backward'], key=report['Details']['forward_backward'].get)\n",
    "                    perc = report['Details']['forward_backward'][event]\n",
    "\n",
    "                    text = f\"\"\"{text} The piecharts on the right shows a more detailed breakdown. \n",
    "                    It shows that {int(perc)}% of the time was spent in event {event}\"\"\"\n",
    "\n",
    "                    plot = create_piechart(report['Details']['forward_backward'], \n",
    "                                        height=350,\n",
    "                                        width=600,\n",
    "                                        x1=0.2,\n",
    "                                        x2=0.6,\n",
    "                                        radius=0.3, \n",
    "                                        title=\"Ratio between forward and backward pass\") \n",
    "                    plots.append(plot)\n",
    "\n",
    "                if len(plots) > 0:\n",
    "                    paragraph = Paragraph(text=text, width=900)\n",
    "                    show(column(paragraph, row(plots)))\n",
    "\n",
    "                plots = []\n",
    "                text = \"\"\n",
    "                if 'ratio' in report['Details'] and len(report['Details']['ratio']) > 0:\n",
    "\n",
    "                    key = list(report['Details']['ratio'].keys())[0]\n",
    "                    ratio = report['Details']['ratio'][key]\n",
    "\n",
    "                    text = f\"\"\"The following piechart shows a breakdown of the CPU/GPU operators that happened \n",
    "                    during I/O bottlenecks. It shows that {int(ratio)}% of the time was spent in executing operators in {key}.\"\"\"\n",
    "\n",
    "                    plot = create_piechart(report['Details']['ratio'], \n",
    "                                            height=350,\n",
    "                                            width=600,\n",
    "                                            x1=0.2,\n",
    "                                            x2=0.6,\n",
    "                                            radius=0.3, \n",
    "                                            title=\"Ratio between CPU/GPU operators\")\n",
    "                    plots.append(plot)\n",
    "\n",
    "\n",
    "                if 'general' in report['Details'] and len(report['Details']['general']) > 0:\n",
    "\n",
    "                    event = max(report['Details']['general'], key=report['Details']['general'].get)\n",
    "                    perc = report['Details']['general'][event]\n",
    "\n",
    "                    plot = create_piechart(report['Details']['general'], \n",
    "                                        height=350,\n",
    "                                        width=600,\n",
    "                                        x1=0.2,\n",
    "                                        x2=0.6,\n",
    "                                        radius=0.3, \n",
    "                                        title=\"General metrics recorded in framework \")\n",
    "                    plots.append(plot)\n",
    "\n",
    "                if len(plots) > 0:\n",
    "                    paragraph = Paragraph(text=text, width=900)\n",
    "                    show(column(paragraph, row(plots)))\n",
    "\n",
    "                plots = []\n",
    "                text = \"\"\n",
    "                if 'horovod' in report['Details'] and len(report['Details']['horovod']) > 0:\n",
    "\n",
    "                    event = max(report['Details']['horovod'], key=report['Details']['horovod'].get)\n",
    "                    perc = report['Details']['horovod'][event]\n",
    "                    text = f\"\"\"The following piechart shows a detailed breakdown of the Horovod metrics that have been\n",
    "                    recorded when I/O bottleneck happened. The most expensive function was {event} with {int(perc)}%\"\"\"\n",
    "\n",
    "                    plot = create_piechart(report['Details']['horovod'], \n",
    "                                        height=350,\n",
    "                                        width=600,\n",
    "                                        x1=0.2,\n",
    "                                        x2=0.6,\n",
    "                                        radius=0.3, \n",
    "                                        title=\"General metrics recorded in framework \")\n",
    "\n",
    "                    paragraph = Paragraph(text=text, width=900)\n",
    "                    show(column(paragraph, row(plot)))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    " \n",
    "if analyse_phase == \"training\": \n",
    "    display(Markdown(\"\"\"#### LoadBalancing in multi-GPU training\\n\\n\"\"\")) \n",
    "    report = load_report('LoadBalancing')\n",
    "    if report:\n",
    "        params = report['RuleParameters'].split('\\n')\n",
    "        threshold = params[0].split(':')[1]\n",
    "        patience = params[1].split(':')[1]\n",
    "        paragraph = Paragraph(text=f\"\"\"The LoadBalancing rule helps to detect issues in workload balancing \n",
    "        between multiple GPUs. \n",
    "        It computes a histogram of GPU utilization values for each GPU and compares then the \n",
    "        similarity between histograms. The rule checked if the distance of histograms is larger than the \n",
    "        threshold of {threshold}%.\n",
    "        During initialization utilization is likely 0, so the rule skipped the first {patience} datapoints.\n",
    "        \"\"\", width=900)\n",
    "        show(paragraph)\n",
    "        \n",
    "        if len(report['Details']) > 0:\n",
    "            for node_id in report['Details']: \n",
    "                \n",
    "                \n",
    "                text = f\"\"\"The following histogram shows the workloads on node {node_id} \n",
    "                which differ by more than threshold {threshold}. \n",
    "                You can enable/disable the visualization of a workload by clicking on the label in the legend.\"\"\"\n",
    "                \n",
    "                plot = figure(plot_height=350, \n",
    "                              plot_width=350, \n",
    "                              x_range=(-1,100),\n",
    "                              title=f\"\"\"Workloads on node {node_id}\"\"\")\n",
    "                colors = bokeh.palettes.viridis(len(report['Details'][node_id]['workloads']))\n",
    "                \n",
    "                for index, gpu_id2 in enumerate(report['Details'][node_id]['workloads']):\n",
    "\n",
    "                    if gpu_id2 in report['Details'][node_id]['distances']:\n",
    "                        for gpu_id1 in report['Details'][node_id]['distances'][gpu_id2]:\n",
    "\n",
    "                            distance = round(report['Details'][node_id]['distances'][gpu_id2][gpu_id1], 2)\n",
    "                            text = f\"\"\"{text} The difference of workload between {gpu_id2} and {gpu_id1} is: {distance}.\"\"\"\n",
    "\n",
    "                    probs = report['Details'][node_id]['workloads'][gpu_id2]\n",
    "                    plot.quad( top=probs,\n",
    "                                bottom=0,\n",
    "                                left=np.arange(0,98,2),\n",
    "                                right=np.arange(2,100,2),\n",
    "                                line_color=\"white\",\n",
    "                                fill_color=colors[index],\n",
    "                                fill_alpha=0.8,\n",
    "                                legend=gpu_id2 )\n",
    "\n",
    "                    plot.y_range.start = 0\n",
    "                    plot.xaxis.axis_label = f\"\"\"Utilization\"\"\"\n",
    "                    plot.yaxis.axis_label = \"Occurrences\"\n",
    "                    plot.grid.grid_line_color = \"white\"\n",
    "                    plot.legend.click_policy=\"hide\"\n",
    "\n",
    "                paragraph = Paragraph(text=f\"\"\"{text}\"\"\", width=900)\n",
    "                show(column(paragraph, plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "if analyse_phase == \"training\":\n",
    "    display(Markdown(\"\"\"#### GPU memory analysis\\n\\n\"\"\"))\n",
    "    \n",
    "    report = load_report('GPUMemoryIncrease')\n",
    "    if report:\n",
    "        params = report['RuleParameters'].split('\\n')\n",
    "        increase = float(params[0].split(':')[1])\n",
    "        patience = params[1].split(':')[1]\n",
    "        window = params[2].split(':')[1]\n",
    "        violations = report['Violations']\n",
    "        \n",
    "        text=Paragraph(text=f\"\"\"The GPUMemoryIncrease rule helps to detect large increase in memory usage on GPUs. \n",
    "        The rule checked if the moving average of memory increased by more than {increase}%. \n",
    "        So if the moving average increased for instance from 10% to {11+increase}%, \n",
    "        the rule would have triggered. During initialization utilization  is likely 0, so the rule skipped the first {patience} datapoints.\n",
    "        The moving average was computed on a window size of {window} continuous datapoints. The rule detected {violations} violations\n",
    "        where the moving average between previous and current time window increased by more than {increase}%\"\"\",\n",
    "                       width=900)\n",
    "        show(text)\n",
    "\n",
    "        if len(report['Details']) > 0:\n",
    "            \n",
    "            timestamp = us_since_epoch_to_human_readable_time(report['Details']['last_timestamp'])\n",
    "            date = datetime.datetime.strptime(timestamp, '%Y-%m-%dT%H:%M:%S:%f')\n",
    "            day = date.date().strftime(\"%m/%d/%Y\")\n",
    "            hour = date.time().strftime(\"%H:%M:%S\")\n",
    "            text = Paragraph(text=f\"\"\"Your training job triggered memory spikes. \n",
    "            The last time the GPUMemoryIncrease rule triggered in your training job was on {day} at {hour}.\n",
    "            The following boxplots are a snapshot from this timestamp that show for each node and GPU the corresponding\n",
    "            memory utilization (without outliers).\"\"\", width=900)\n",
    "            show(text)\n",
    "            \n",
    "            del report['Details']['last_timestamp']\n",
    "            \n",
    "            for node_id in report['Details']:\n",
    "    \n",
    "                plot = figure(plot_height=350, \n",
    "                          plot_width=1000,\n",
    "                          toolbar_location='right',\n",
    "                          tools=\"hover,wheel_zoom,reset,pan\", \n",
    "                          title=f\"Node {node_id}\",\n",
    "                          x_range=(0,17),\n",
    "                          )\n",
    "\n",
    "                for index, key in enumerate(report['Details'][node_id]):\n",
    "                    display(Markdown(f\"\"\"**Memory utilization of {key} on node {node_id}:**\"\"\"))\n",
    "                    text = \"\"\n",
    "                    gpu_max = report['Details'][node_id][key]['gpu_max']\n",
    "                    text = f\"\"\"{text} The max memory utilization of {key} on node {node_id} was {gpu_max}%.\"\"\"\n",
    "                    \n",
    "                    p_95 = int(report['Details'][node_id][key]['p95'])\n",
    "                    p_5 = report['Details'][node_id][key]['p05']\n",
    "                    if p_95 < int(50): \n",
    "                        text = f\"\"\"{text} The 95th percentile was only {p_95}%.\"\"\"\n",
    "                    if p_5 < int(5): \n",
    "                        text = f\"\"\"{text} The 5th percentile was only {p_5}%.\"\"\"\n",
    "                    if p_95 - p_5 > 50:\n",
    "                        text = f\"\"\"{text} The difference between 5th quantile {p_5}% and 95th quantile {p_95}% is quite \n",
    "                        significant, which means that memory utilization on {key} is fluctuating quite a lot.\"\"\"\n",
    "                        \n",
    "                    text = Paragraph(text=f\"\"\"{text}\"\"\", width=900)\n",
    "                    show(text)\n",
    "                    \n",
    "                    upper = report['Details'][node_id][key]['upper']\n",
    "                    lower = report['Details'][node_id][key]['lower']\n",
    "                    p75 = report['Details'][node_id][key]['p75']\n",
    "                    p25 = report['Details'][node_id][key]['p25']\n",
    "                    p50 = report['Details'][node_id][key]['p50']\n",
    "\n",
    "                    plot.segment(index+1, upper, index+1, p75, line_color=\"black\")\n",
    "                    plot.segment(index+1, lower, index+1, p25, line_color=\"black\")\n",
    "\n",
    "                    plot.vbar(index+1, 0.7, p50, p75, fill_color=\"#FDE725\", line_color=\"black\")\n",
    "                    plot.vbar(index+1, 0.7, p25, p50, fill_color=\"#440154\", line_color=\"black\")\n",
    "\n",
    "                    plot.rect(index+1, lower, 0.2, 0.01, line_color=\"black\")\n",
    "                    plot.rect(index+1, upper, 0.2, 0.01, line_color=\"black\")\n",
    "\n",
    "                    plot.xaxis.major_label_overrides[index+1] = key\n",
    "                    plot.xgrid.grid_line_color = None\n",
    "                    plot.ygrid.grid_line_color = \"white\"\n",
    "                    plot.grid.grid_line_width = 0\n",
    "\n",
    "                    plot.xaxis.major_label_text_font_size=\"10px\"\n",
    "                plot.xaxis.ticker = np.arange(index+2)\n",
    "                \n",
    "                show(plot)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
