{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker EagleEye TensorFlow Training Job Example\n",
    "\n",
    "This notebook will walk you through creating a TensorFlow training job with the SageMaker EagleEye feature enabled.\n",
    "\n",
    "# 1. Install Dependencies\n",
    "\n",
    "\n",
    "### SageMaker Python SDK\n",
    "\n",
    "Install the private beta version of the SageMaker Python SDK library. This enables you to call a private version of the SageMaker EagleEye API that allows you to create SageMaker training jobs with the profiler enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ../sdk/sagemaker-1.60.3.dev0.tar.gz -q\n",
    "\n",
    "# The following command will enable the SDK to use new profiler configs in the API\n",
    "! aws configure add-model --service-model file://../sdk/sagemaker-2017-07-24.normal.json --service-name sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run this notebook in Jupyterlab and not Jupyter, you need to install the jupyterlab extensions \n",
    "`@jupyter-widgets/jupyterlab-manager` and `@bokeh/jupyter_bokeh`. We provide a [SageMaker Lifecycle configuration](lifecycle_config/on_start.sh) that automatically installs these extensions when your notebook instance is started. Check out [this blog](https://aws.amazon.com/blogs/machine-learning/customize-your-amazon-sagemaker-notebook-instances-with-lifecycle-configurations-and-the-option-to-disable-internet-access/) for how to create and attach a Lifecycle configuration to your notebook instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create a Training Job with Profiling Enabled<a class=\"anchor\" id=\"option-1\"></a>\n",
    "\n",
    "You will use the standard [SageMaker Estimator API for Tensorflow](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html#tensorflow-estimator) to create training jobs. To enable profiling, create a `ProfilerConfig` object and pass it to the `profiler_config` parameter of the `TensorFlow` estimator.\n",
    "\n",
    "### Define hyperparameters\n",
    "\n",
    "Define hyperparameters such as number of epochs, batch size, and data augmentation. You can increase batch size to increases system utilization, but it may result in CPU bottlneck problems. Data preprocessing of a large batch size with augmentation requires a heavy computation. You can disable data_augmentation to see the impact on the system utilization. \n",
    "\n",
    "For demonstration purpose, the following hyperparameters are prepared to increase CPU usage, leading to GPU starvation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'epoch': 5, \n",
    "                   'batch_size': 64,\n",
    "                   'data_augmentation': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set `region` and the `image_name` for your training job with the TensorFlow framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "\n",
    "# EagleEye beta version base image for TensorFlow\n",
    "image_name = f'385479125792.dkr.ecr.{region}.amazonaws.com/profiler-gpu:latest'\n",
    "print(f\"image being used is {image_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set a profiler configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.profiler import ProfilerConfig \n",
    "\n",
    "profiling_parameters = {\n",
    "    \"ProfilerEnabled\": str(True),\n",
    "    \"GeneralMetricsConfig\": \"{\\\"StartStep\\\": \\\"2\\\", \\\"NumSteps\\\": \\\"2\\\"}\"\n",
    "}\n",
    "profiler_config = ProfilerConfig(\n",
    "    profiling_interval_millis=500,\n",
    "    profiling_parameters=profiling_parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "# This parameter tells sagemaker how to configure and run horovod. \n",
    "# If you use a bigger instance with more than 4 GPUs per node, change the process_per_host paramter accordingly.\n",
    "distributions = {\n",
    "                    \"mpi\": {\n",
    "                        \"enabled\": True,\n",
    "                        \"processes_per_host\": 4,\n",
    "                        \"custom_mpi_options\": \"-verbose -x HOROVOD_TIMELINE=./hvd_timeline.json -x NCCL_DEBUG=INFO -x OMPI_MCA_btl_vader_single_copy_mechanism=none\",\n",
    "                    }\n",
    "                }\n",
    "job_name=\"multi-node-multi-gpu-tf-hvd\"\n",
    "instance_count=2\n",
    "entry_script='tf-hvd-train.py'\n",
    "\n",
    "\"\"\"\n",
    "# Uncomment this block if you want to run single node multi gpu horovod training job.\n",
    "\n",
    "## This parameter tells sagemaker how to configure and run horovod. If you want to use more than 4 GPUs per node then change the process_per_host paramter accordingly.\n",
    "distributions = {\n",
    "                    \"mpi\": {\n",
    "                        \"enabled\": True,\n",
    "                        \"processes_per_host\": 4,\n",
    "                        \"custom_mpi_options\": \"-verbose -x HOROVOD_TIMELINE=./hvd_timeline.json -x NCCL_DEBUG=INFO -x OMPI_MCA_btl_vader_single_copy_mechanism=none\",\n",
    "                    }\n",
    "                }\n",
    "job_name=\"single-node-multi-gpu-tf-hvd\"\n",
    "instance_count=1\n",
    "entry_script='tf-hvd-train.py'\n",
    "\"\"\"\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    base_job_name=job_name,\n",
    "    image_name=image_name,\n",
    "    train_instance_count=instance_count,\n",
    "    train_instance_type='ml.p3.8xlarge',\n",
    "    entry_point=entry_script,\n",
    "    source_dir='demo',\n",
    "    framework_version='2.2.0',\n",
    "    py_version='py37',\n",
    "    profiler_config=profiler_config,\n",
    "    script_mode=True,\n",
    "    hyperparameters=hyperparameters,\n",
    "    distributions=distributions,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training job\n",
    "\n",
    "The following `estimator.fit()` with `wait=False` argument initiates the training job in the background. You can proceed to run the dashboard or analysis notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Retrieve the Training Job Name to Analyze Profiling Data\n",
    "\n",
    "Copy outputs of the following cell (`training_job_name` and `region`) to run the analysis notebooks `eagleeye_generic_dashboard.ipynb`, `analyze_performance_bottlenecks.ipynb`, and `eagleeye_interactive_analysis.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "\n",
    "training_job_name = estimator.latest_training_job.name\n",
    "print(f\"Training jobname: {training_job_name}\")\n",
    "print(f\"Region: {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Run SageMaker EagleEye rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell runs a profiler rule processing container on a separte instance in parallel. EagleEye will fetch the system and framework metrics and analyze the data for potential performance issues. \n",
    "\n",
    "You can run the rule container at any time while the training job is in progress or after the job has finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import Processor, ProcessingInput, ProcessingOutput\n",
    "\n",
    "profiler_rule_image=f'385479125792.dkr.ecr.{region}.amazonaws.com/sagemaker-profiler-rules-container:latest'\n",
    "\n",
    "processor = Processor(\n",
    "            role=sagemaker.get_execution_role(),\n",
    "            image_uri=profiler_rule_image,\n",
    "            instance_count=1,\n",
    "            instance_type='ml.r5.4xlarge',\n",
    "            env={'S3_PATH': estimator.latest_job_profiler_artifacts_path()}\n",
    "        )\n",
    "processor.run([], \n",
    "              [ProcessingOutput(output_name='profiler-analysis', \n",
    "                                source='/opt/ml/processing/outputs', \n",
    "                                destination=estimator.latest_job_profiler_artifacts_path())],\n",
    "              wait=False, logs=False\n",
    "             ) \n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the processing job finished you will find an html report `plot-viz-rule.html` and a notebook `profiler-report.ipynb` in your S3 bucket. Each rule also creates a json-file that is used to generate the final report and you can find those files in your S3 bucket under `profiler-reports`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"You will find the profiler report in {estimator.latest_job_profiler_artifacts_path()}/plot_viz_rule.html after the training has finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
