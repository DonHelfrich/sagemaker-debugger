{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS SageMaker Profiler Example\n",
    "\n",
    "This notebook will walk you through creating a training job with the profiler feature enabled.\n",
    "\n",
    "# 1. Install Dependencies\n",
    "\n",
    "\n",
    "### SageMaker Python SDK and `smdebug`\n",
    "\n",
    "The first thing you will need to do is install the private beta versions of the SageMaker Python SDK and the `smdebug` library. This will enable you to call a private version of the API that allows you to create SageMaker training jobs with the profiler enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ../sdk/sagemaker-1.60.3.dev0.tar.gz -q\n",
    "! pip install ../sdk/smdebug-0.8.0b20200622-py3-none-any.whl\n",
    "\n",
    "# The following command will enable the SDK to use new profiler configs in the API\n",
    "! aws configure add-model --service-model file://../sdk/sagemaker-2017-07-24.normal.json --service-name sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run this notebook in Jupyterlab and not Jupyter, you need to install the jupyterlab extensions \n",
    "`@jupyter-widgets/jupyterlab-manager` and `@bokeh/jupyter_bokeh`. We provide a [SageMaker Lifecycle configuration](lifecycle_config/on_start.sh) that automatically installs these extensions when your notebook instance is started. Check out [this blog](https://aws.amazon.com/blogs/machine-learning/customize-your-amazon-sagemaker-notebook-instances-with-lifecycle-configurations-and-the-option-to-disable-internet-access/) for how to create and attach a Lifecycle configuration to your notebook instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create A Training Job With Profiling Enabled\n",
    "\n",
    "You will use the standard [SageMaker Estimator API for Tensorflow](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html#tensorflow-estimator) to create training jobs. To create a training job with the profiler enabled, all you need to do is create a `ProfilerConfig` object and pass it into the `profiler_config` parameter of an `Estimator`.\n",
    "\n",
    "### Define an Estimator\n",
    "\n",
    "We define some hyperparameters such as number of epochs, batch size and enable data augmentation. You can increase batch size which leads to higher system utilization but may introduce a CPU bottlneck since data preprocessing and augmentation is very compute heavy. Larger batch size means more data has to be preprocessed more quickly. Alternatively, you can disable data_augmentation to see the impact on the system utilization. \n",
    "\n",
    "For demonstration purposes we choose a set of data augmentation techniques that will heavily increase CPU usage leading to GPU starvation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'epoch': 10, \n",
    "                   'batch_size': 64,\n",
    "                   'data_augmentation': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.profiler import ProfilerConfig \n",
    "\n",
    "estimator = TensorFlow(\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    image_name='385479125792.dkr.ecr.us-east-2.amazonaws.com/profiler-gpu:latest',\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.p3.8xlarge',\n",
    "    entry_point='train.py',\n",
    "    source_dir='demo',\n",
    "    framework_version='2.2.0',\n",
    "    py_version='py37',\n",
    "    profiler_config=ProfilerConfig(profiling_interval_millis=500),\n",
    "    script_mode=True,\n",
    "    hyperparameters=hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Read Profiler Data\n",
    "\n",
    "### Get the S3 path where profiler data is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = estimator.latest_job_profiler_artifacts_path()\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read profiler data: system metrics\n",
    "\n",
    "Once the training job is running SageMaker will collect system and framework metrics. The following code cell is waiting for the system metrics to become available in S3. Once they are available you will be able to query and plot those metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdebug.profiler.system_metrics_reader import S3SystemMetricsReader\n",
    "import time\n",
    "\n",
    "system_metrics_reader = S3SystemMetricsReader(path)\n",
    "\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "training_job_name = estimator.latest_training_job.name\n",
    "print(f\"Training job name: {training_job_name}\")\n",
    "\n",
    "training_job_status = ''\n",
    "training_job_secondary_status = ''\n",
    "while system_metrics_reader.get_timestamp_of_latest_available_file() == 0:\n",
    "    system_metrics_reader.refresh_event_file_list()\n",
    "    client = sagemaker_client.describe_training_job(\n",
    "        TrainingJobName=training_job_name\n",
    "    )\n",
    "    if 'TrainingJobStatus' in client:\n",
    "        training_job_status = f\"TrainingJobStatus: {client['TrainingJobStatus']}\"\n",
    "    if 'SecondaryStatus' in client:\n",
    "        training_job_secondary_status = f\"TrainingJobSecondaryStatus: {client['SecondaryStatus']}\"\n",
    "        \n",
    "    print(f\"Profiler data from system not available yet. {training_job_status}. {training_job_secondary_status}.\")\n",
    "    time.sleep(20)\n",
    "\n",
    "print(\"\\n\\nProfiler data from system is available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to convert timestamps into UTC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def timestamp_to_utc(timestamp):\n",
    "    utc_dt = datetime.utcfromtimestamp(timestamp)\n",
    "    return utc_dt.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is available we can query and inspect it. We get the latest available timestamp and query all the events within the given timerange:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_metrics_reader.refresh_event_file_list()\n",
    "last_timestamp = system_metrics_reader.get_timestamp_of_latest_available_file()\n",
    "events = system_metrics_reader.get_events(0, last_timestamp) \n",
    "\n",
    "print(\"Found\", len(events), \"recorded system metric events. Latest recorded event:\",  \n",
    "      timestamp_to_utc(last_timestamp/1000000))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can iterate over the list of recorded events. Let's have a look on the first event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Event name:\", events[0].name, \n",
    "      \"\\nTimestamp:\", timestamp_to_utc(events[0].timestamp), \n",
    "      \"\\nValue:\", events[0].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary view - GPU and CPU usage \n",
    "\n",
    "This notebook provides dashboards to aggregate and visualize the profiler data in real-time. \n",
    "\n",
    "MetricHistogram computes a histogram on GPU and CPU utilization values. Bins are between 0 and 100. Good system utilization means that the center of the distribtuon should be between 80 to 90. As example:\n",
    "<table><tr>\n",
    "<td> <img src=\"images/histogram1.png\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "<td> <img src=\"images/histogram2.png\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "First image shows good utilization pattern. Second one indicates high fluctuations because distribution has a spike at 0 and 100. In case of multi-GPU training: if distributions of GPU utilization values are not similar it indicates an issue with workload distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import MetricsHistogram  \n",
    "\n",
    "system_metrics_reader.refresh_event_file_list()\n",
    "metrics_histogram = MetricsHistogram(system_metrics_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read profiler data: framework annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdebug.profiler.algorithm_metrics_reader import S3AlgorithmMetricsReader\n",
    "\n",
    "framework_metrics_reader = S3AlgorithmMetricsReader(path)\n",
    "\n",
    "events = []\n",
    "while framework_metrics_reader.get_timestamp_of_latest_available_file() == 0 or len(events) == 0:\n",
    "    framework_metrics_reader.refresh_event_file_list()\n",
    "    last_timestamp = framework_metrics_reader.get_timestamp_of_latest_available_file()\n",
    "    events = framework_metrics_reader.get_events(0, last_timestamp)\n",
    "    \n",
    "    print(\"Profiler data from framework not available yet\")\n",
    "    time.sleep(20)\n",
    "        \n",
    "print(\"\\n\\n Profiler data from framework is available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell retrieves all recorded events from Amazon S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framework_metrics_reader.refresh_event_file_list()\n",
    "last_timestamp = framework_metrics_reader.get_timestamp_of_latest_available_file()\n",
    "events = framework_metrics_reader.get_events(0, last_timestamp) \n",
    "\n",
    "print(\"Found\", len(events), \"recorded framework annotations. Latest event recorded \",  \n",
    "      timestamp_to_utc(last_timestamp/1000000))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before we can inspect the recorded events. Since we are reading framework metrics there is now a start and end time for each event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Event name:\", events[0].event_name, \n",
    "      \"\\nStart time:\", timestamp_to_utc(events[0].start_time/1000000000), \n",
    "      \"\\nEnd time:\", timestamp_to_utc(events[0].end_time/1000000000), \n",
    "      \"\\nDuration:\", events[0].duration, \"nanosecond\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step durations over time\n",
    "\n",
    "SageMaker Debugger records the durations of each step, which is the time spent in one forward and backward pass. The following code cell plots step durations (y-axis) over training job duration (x-axis). Typically we would expect the step duration to be very similar across the training run. Signficant outliers are an indication of a bottleneck. `StepTimelineChart` helps to identify if such outliers happen in regular intervals. Following image shows an example, where the step duration mostly lasts about 200 to 250ms but every 10th step a spike occurs where step duration is significantly higher (600-800ms).  ![](images/step_duration.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils import StepTimelineChart\n",
    "\n",
    "framework_metrics_reader.refresh_event_file_list()\n",
    "view_step_timeline_chart = StepTimelineChart(framework_metrics_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers in step duration\n",
    "\n",
    "StepHistogram creates a histogram of step duration values. Signficant outliers are an indication of a bottleneck. In contrast to `SetpTimelineChart` it allows to more easily identify clusters of step duration values. As a simple example: time spent during training phase (forward+backward pass) will likely be different to time spent during validation phase (forward pass), so we would expect at least two clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import StepHistogram\n",
    "\n",
    "framework_metrics_reader.refresh_event_file_list()\n",
    "step_histogram = StepHistogram(framework_metrics_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeline charts \n",
    "\n",
    "The following class create  timeline charts for utilization per core and GPU. It will show the last 1000 datapoints and charts will get updated by the last code cell in the end of this notebook. Once updated you can inspect previous datapoints by zooming out of the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils import TimelineCharts\n",
    "\n",
    "view_timeline_charts  = TimelineCharts(system_metrics_reader, framework_metrics_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the BoxSelectTool to make a selection in the timeline chart.\n",
    "\n",
    "<img src='images/boxselect.png' width=\"840\" height=\"180\" border=\"10\" />\n",
    "\n",
    "\n",
    "The following code cell identifies which time annotations have been recorded in the training job for the selected timerange:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "view_timeline_charts.find_time_annotations([]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap \n",
    "\n",
    "The following code cell creates a heatmap where each row corresponds to one metric (CPU core and GPU utilizations) and x-axis is the duration of the training job. It allows to more easily spot CPU bottlenecks e.g. if utilization on GPU is low but a utilization of one or more cores is high. \n",
    "\n",
    "For instance the following example shows the heatmap of a training job that has been using 4 GPUs and 8 CPU cores. The first 4 rows show the GPUs utilization, the remaining rows the utilization on CPU cores. Yellow indicates maximum utilization, purple means that utilization was 0. GPUs have frequent stalled cycles where utilization is dropping to 0 while at the same time utilization on CPU cores is at a maximum. This is a clear indication of a CPU bottleneck where GPUs are waiting for the data to arrive. Such a bottleneck can be caused for instance by a too compute-heavy pre-processing.\n",
    "\n",
    "![](images/heatmap.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import Heatmap\n",
    "\n",
    "view_heatmap = Heatmap(system_metrics_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run loop to fetch latest profiler data and update charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = estimator.latest_training_job.name\n",
    "print('Training job name: {}'.format(job_name))\n",
    "\n",
    "client = estimator.sagemaker_session.sagemaker_client\n",
    "\n",
    "description = client.describe_training_job(TrainingJobName=job_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import push_notebook\n",
    "import time \n",
    "\n",
    "last_timestamp = system_metrics_reader.get_timestamp_of_latest_available_file() \n",
    "\n",
    "\n",
    "while description['TrainingJobStatus'] == \"InProgress\":\n",
    "    system_metrics_reader.refresh_event_file_list()\n",
    "    framework_metrics_reader.refresh_event_file_list()\n",
    "    current_timestamp = system_metrics_reader.get_timestamp_of_latest_available_file()  \n",
    "    description = client.describe_training_job(TrainingJobName=job_name)\n",
    "    \n",
    "    if current_timestamp > last_timestamp:  \n",
    "        \n",
    "        print(\"New data available, updating dashboards. Current timestamp is\", \n",
    "              timestamp_to_utc(current_timestamp/1000000))\n",
    "        \n",
    "        view_timeline_charts.update_data(current_timestamp)\n",
    "        push_notebook(handle=view_timeline_charts.target)\n",
    "\n",
    "        view_step_timeline_chart.update_data(current_timestamp)\n",
    "        push_notebook(handle=view_step_timeline_chart.target)\n",
    "\n",
    "        view_heatmap.update_data(current_timestamp)\n",
    "        push_notebook(handle=view_heatmap.target) \n",
    "\n",
    "        metrics_histogram.update_data(current_timestamp)\n",
    "        push_notebook(handle=metrics_histogram.target)\n",
    "\n",
    "        step_histogram.update_data(current_timestamp)\n",
    "        push_notebook(handle=step_histogram.target)\n",
    "\n",
    "        last_timestamp = current_timestamp\n",
    "    time.sleep(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
